{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "802ff607-0e6f-4cfa-96c1-0fa7782af4c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be2054f-e22e-49f4-80bd-c80315b055e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c46a95e4-c5b9-4159-958f-2b8e38376764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.functions import year,month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9647b926-1a88-4cf3-92a8-02df013166c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#ingesta de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69371157-42f1-418e-8c80-d448a0b6a5cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "SP500_UNIVERSE = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"JPM\", \"JNJ\", \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\",\n",
    "    \"NFLX\", \"ADBE\"\n",
    "]\n",
    "\n",
    "def ingest_ticker(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "    data = yf.download(ticker, start=start, end=end, auto_adjust=True)\n",
    "    data = data.reset_index()\n",
    "    data.columns = [c[0].lower().replace(\" \", \"_\") for c in data.columns]\n",
    "    data[\"ticker\"] = ticker\n",
    "    return data\n",
    "\n",
    "def transform(prices_pdf: pd.DataFrame):\n",
    "    prices_sdf = spark.createDataFrame(prices_pdf)\n",
    "    return (prices_sdf.withColumn(\"year\",year(col(\"date\")))\n",
    "                .withColumn(\"month\",month(col(\"date\")))\n",
    "                .withColumn(\"date\",to_date(col(\"date\"))))\n",
    "def load(prices_sdf: DataFrame, path: str):\n",
    "    (prices_sdf.write\n",
    "                .option(\"overwriteSchema\", \"True\")\n",
    "                .format(\"delta\")\n",
    "                .mode(\"overwrite\")\n",
    "                .partitionBy(\"ticker\",\"year\")\n",
    "                .save(path))\n",
    "    \n",
    "prices_df = pd.DataFrame()\n",
    "print(f\"Tipo de prices_df antes del bucle: {type(prices_df)}\")\n",
    "for ticker in SP500_UNIVERSE:\n",
    "    df = ingest_ticker(ticker, \"2021-01-01\", \"2024-12-31\")\n",
    "    prices_df = pd.concat([prices_df,df])\n",
    "transformed = transform(prices_df)\n",
    "load(transformed, \"/Volumes/market-mood/processed/prices_clean\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8491d904-0c59-4142-ad17-e2fe97c609ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SP500_UNIVERSE = [\n",
    "#     \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "#     \"JPM\", \"JNJ\", \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\",\n",
    "#     \"NFLX\", \"ADBE\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# def ingest_ticker(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "#     data = yf.download(ticker, start=start, end=end, auto_adjust=True)\n",
    "#     data = data.reset_index()\n",
    "#     data.columns = [c[0].lower().replace(\" \", \"_\") for c in data.columns]\n",
    "#     data[\"ticker\"] = ticker\n",
    "#     return data\n",
    "\n",
    "    \n",
    "\n",
    "# def extract(tickers: list, start: str, end: str) -> pd.DataFrame:\n",
    "#     prices_df = pd.DataFrame()\n",
    "#     print(f\"Tipo de prices_df antes del bucle: {type(prices_df)}\")\n",
    "#     for ticker in tickers:\n",
    "#         df = ingest_ticker(ticker, start, end)\n",
    "#         prices_df = pd.concat([prices_df,df])\n",
    "#     return prices_df\n",
    "\n",
    "# def transform(prices_pdf: pd.DataFrame):\n",
    "#     prices_sdf = spark.createDataFrame(prices_pdf)\n",
    "#     return (prices_sdf.withColumn(\"year\",year(col(\"date\")))\n",
    "#                 .withColumn(\"month\",month(col(\"date\")))\n",
    "#                 .withColumn(\"date\",to_date(col(\"date\"))))\n",
    "\n",
    "\n",
    "\n",
    "# def load(prices_sdf: DataFrame, path: str):\n",
    "#     (prices_sdf.write\n",
    "#                 .option(\"overwriteSchema\", \"True\")\n",
    "#                 .format(\"delta\")\n",
    "#                 .mode(\"overwrite\")\n",
    "#                 .partitionBy(\"ticker\",\"year\")\n",
    "#                 .save(path))\n",
    "\n",
    "# # Ejecuci√≥n principal\n",
    "# if __name__ == \"__main__\":\n",
    "#     raw = extract(SP500_UNIVERSE, \"2021-01-01\", \"2024-12-31\")\n",
    "#     transformed = transform(raw)\n",
    "#     load(transformed, \"/Volumes/market-mood/raw/prices\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "financeIngestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
