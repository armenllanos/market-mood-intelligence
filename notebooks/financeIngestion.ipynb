{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "802ff607-0e6f-4cfa-96c1-0fa7782af4c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9be2054f-e22e-49f4-80bd-c80315b055e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n  Downloading yfinance-1.2.0-py2.py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: pandas>=1.3.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.1.3)\nRequirement already satisfied: requests>=2.31 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.32.3)\nCollecting multitasking>=0.0.7 (from yfinance)\n  Downloading multitasking-0.0.12.tar.gz (19 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: platformdirs>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: pytz>=2022.5 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2024.1)\nCollecting frozendict>=2.3.4 (from yfinance)\n  Downloading frozendict-2.4.7-py3-none-any.whl.metadata (23 kB)\nCollecting peewee>=3.16.2 (from yfinance)\n  Downloading peewee-4.0.0-py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (4.12.3)\nCollecting curl_cffi<0.14,>=0.7 (from yfinance)\n  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (13 kB)\nRequirement already satisfied: protobuf>=3.19.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (5.29.4)\nCollecting websockets>=13.0 (from yfinance)\n  Downloading websockets-16.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl.metadata (6.8 kB)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: cffi>=1.12.0 in /databricks/python3/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /databricks/python3/lib/python3.12/site-packages (from curl_cffi<0.14,>=0.7->yfinance) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.3.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi<0.14,>=0.7->yfinance) (2.21)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\nDownloading yfinance-1.2.0-py2.py3-none-any.whl (130 kB)\nDownloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (7.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/7.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.9/7.9 MB\u001B[0m \u001B[31m89.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading frozendict-2.4.7-py3-none-any.whl (16 kB)\nDownloading peewee-4.0.0-py3-none-any.whl (139 kB)\nDownloading websockets-16.0-cp312-cp312-manylinux2014_aarch64.manylinux_2_17_aarch64.manylinux_2_28_aarch64.whl (186 kB)\nBuilding wheels for collected packages: multitasking\n  Building wheel for multitasking (setup.py): started\n  Building wheel for multitasking (setup.py): finished with status 'done'\n  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15548 sha256=ec80dcfc422b2e6432d2b9ef6af72fb0d7dffebf536e4142c66573a44f12fe12\n  Stored in directory: /home/spark-2434c930-fad0-4c7b-9de6-b2/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\nSuccessfully built multitasking\nInstalling collected packages: peewee, multitasking, websockets, frozendict, curl_cffi, yfinance\nSuccessfully installed curl_cffi-0.13.0 frozendict-2.4.7 multitasking-0.0.12 peewee-4.0.0 websockets-16.0 yfinance-1.2.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c46a95e4-c5b9-4159-958f-2b8e38376764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.functions import year,month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9647b926-1a88-4cf3-92a8-02df013166c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#ingesta de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69371157-42f1-418e-8c80-d448a0b6a5cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de prices_df antes del bucle: <class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n\r[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "SP500_UNIVERSE = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "    \"JPM\", \"JNJ\", \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\",\n",
    "    \"NFLX\", \"ADBE\"\n",
    "]\n",
    "\n",
    "def ingest_ticker(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "    data = yf.download(ticker, start=start, end=end, auto_adjust=True)\n",
    "    data = data.reset_index()\n",
    "    data.columns = [c[0].lower().replace(\" \", \"_\") for c in data.columns]\n",
    "    data[\"ticker\"] = ticker\n",
    "    return data\n",
    "\n",
    "    \n",
    "prices_df = pd.DataFrame()\n",
    "print(f\"Tipo de prices_df antes del bucle: {type(prices_df)}\")\n",
    "for ticker in SP500_UNIVERSE:\n",
    "    df = ingest_ticker(ticker, \"2021-01-01\", \"2024-12-31\")\n",
    "    prices_df = pd.concat([prices_df,df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8491d904-0c59-4142-ad17-e2fe97c609ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# SP500_UNIVERSE = [\n",
    "#     \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"META\", \"TSLA\", \"BRK-B\",\n",
    "#     \"JPM\", \"JNJ\", \"V\", \"PG\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"BAC\",\n",
    "#     \"NFLX\", \"ADBE\"\n",
    "# ]\n",
    "\n",
    "\n",
    "# def ingest_ticker(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "#     data = yf.download(ticker, start=start, end=end, auto_adjust=True)\n",
    "#     data = data.reset_index()\n",
    "#     data.columns = [c[0].lower().replace(\" \", \"_\") for c in data.columns]\n",
    "#     data[\"ticker\"] = ticker\n",
    "#     return data\n",
    "\n",
    "    \n",
    "\n",
    "# def extract(tickers: list, start: str, end: str) -> pd.DataFrame:\n",
    "#     prices_df = pd.DataFrame()\n",
    "#     print(f\"Tipo de prices_df antes del bucle: {type(prices_df)}\")\n",
    "#     for ticker in tickers:\n",
    "#         df = ingest_ticker(ticker, start, end)\n",
    "#         prices_df = pd.concat([prices_df,df])\n",
    "#     return prices_df\n",
    "\n",
    "# def transform(prices_pdf: pd.DataFrame):\n",
    "#     prices_sdf = spark.createDataFrame(prices_pdf)\n",
    "#     return (prices_sdf.withColumn(\"year\",year(col(\"date\")))\n",
    "#                 .withColumn(\"month\",month(col(\"date\")))\n",
    "#                 .withColumn(\"date\",to_date(col(\"date\"))))\n",
    "\n",
    "\n",
    "\n",
    "# def load(prices_sdf: DataFrame, path: str):\n",
    "#     (prices_sdf.write\n",
    "#                 .option(\"overwriteSchema\", \"True\")\n",
    "#                 .format(\"delta\")\n",
    "#                 .mode(\"overwrite\")\n",
    "#                 .partitionBy(\"ticker\",\"year\")\n",
    "#                 .save(path))\n",
    "\n",
    "# # Ejecución principal\n",
    "# if __name__ == \"__main__\":\n",
    "#     raw = extract(SP500_UNIVERSE, \"2021-01-01\", \"2024-12-31\")\n",
    "#     transformed = transform(raw)\n",
    "#     load(transformed, \"/Volumes/market-mood/raw/prices\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "financeIngestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}